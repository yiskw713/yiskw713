<img src="https://github.com/yiskw713/yiskw713/blob/master/header.png?raw=true">

<a href="http://yiskw713.github.io">
  <img align="left" src="https://img.shields.io/website?down_color=red&down_message=down&label=MY%20WEBSITE&style=for-the-badge&up_message=up&url=http%3A%2F%2Fyiskw713.github.io" />
</a>
<a href="https://yiskw713.hatenablog.com/">
  <img align="left" src="https://img.shields.io/website?down_color=red&down_message=down&label=MY%20BLOG&style=for-the-badge&up_message=open&up_color=blue&url=https://yiskw713.hatenablog.com/" />
</a>
<a href="https://twitter.com/yciskw_">
  <img align="left" src="https://img.shields.io/twitter/follow/yciskw_?logo=Twitter&style=for-the-badge" />
</a>

<br>
<br>

* 👨‍💻 I'm a first-year PhD candidate, majoring in Computer Vision and Machine Learning. 
* 🧪 My research topic is about human action recognition.
* 😎 I'm curious about everything and I'm currently learning Rust language.
* 🎒 I love traveling all over the world. I've been to over 25 countries and landed on the seven continents so far.
* 🏃⛳️  I've been getting into running a marathon and playing golf lately.

### Languages and Skills

<p>
<img src="https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=Python&logoColor=white"/>
<img src="https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat-square&logo=PyTorch&logoColor=white"/>
<img src="https://img.shields.io/badge/-pandas-150458?style=flat-square&logo=pandas&logoColor=white"/>
<img src="https://img.shields.io/badge/-Django-092E20?style=flat-square&logo=Django&logoColor=white"/>
<img src="https://img.shields.io/badge/-Rust-000000?style=flat-square&logo=Rust&logoColor=white"/>
<img src="https://img.shields.io/badge/-JavaScript-F7DF1E?style=flat-square&logo=JavaScript&logoColor=black"/>
<img src="https://img.shields.io/badge/-TypeScript-007ACC?style=flat-square&logo=TypeScript&logoColor=white"/>
<img src="https://img.shields.io/badge/-Vue.js-42B883?style=flat-square&logo=Vue-dot-js&logoColor=white"/>
<img src="https://img.shields.io/badge/-Nuxt.js-00C58E?style=flat-square&logo=nuxt-dot-js&logoColor=white"/>
<img src="https://img.shields.io/badge/-C++-00599C?style=flat-square&logo=c%2B%2B&logoColor=white"/>
<img src="https://img.shields.io/badge/-HTML5-E34F26?style=flat-square&logo=HTML5&logoColor=white"/>
<img src="https://img.shields.io/badge/-CSS3-1572B6?style=flat-square&logo=CSS3&logoColor=white"/>
<img src="https://img.shields.io/badge/-Sass-1572B6?style=flat-square&logo=SASS&logoColor=white"/>
<img src="https://img.shields.io/badge/-MySQL-F29111?style=flat-square&logo=MySQL&logoColor=white"/>
<img src="https://img.shields.io/badge/-PostgreSQL-F29111?style=flat-square&logo=PostgreSQL&logoColor=white"/>
<img src="https://img.shields.io/badge/-Visual%20Studio%20Code-23A9F2?style=flat-square&logo=Visual%20Studio%20Code&logoColor=white"/>
<img src="https://img.shields.io/badge/-Vim-1572B6?style=flat-square&logo=Vim&logoColor=white"/>
<img src="https://img.shields.io/badge/-Github-181717?style=flat-square&logo=GitHub&logoColor=white"/>
<img src="https://img.shields.io/badge/-Git-F44D27?style=flat-square&logo=Git&logoColor=white"/>
<img src="https://img.shields.io/badge/-Google%20Cloud-4285F4?style=flat-square&logo=Google%20Cloud&logoColor=white"/>
<img src="https://img.shields.io/badge/-Amazon%20AWS-232F3E?style=flat-square&logo=Amazon%20AWS&logoColor=white"/>
<img src="https://img.shields.io/badge/-Docker-2496ED?style=flat-square&logo=Docker&logoColor=white"/>
</p>

### Where to Find Me 👀

[<img align="left" width="40px" src="https://img.icons8.com/fluent/96/000000/domain.png" />][website]
[<img align="left" width="40px" src="https://img.icons8.com/color/96/000000/twitter-squared.png" />][twitter]
[<img align="left" width="40px" src="https://img.icons8.com/color/96/000000/linkedin.png" />][linkedin]
[<img align="left" width="40px" src="https://img.icons8.com/color/96/000000/instagram-new.png" />][instagram]
[<img align="left" width="40px" src="https://img.icons8.com/color/96/000000/facebook.png" />][facebook]

<br>
<br>

✉️ : yishikawa[at]aoki-medialab.jp
<br>

### Profile 📖

<!-- Education -->
<details>
<summary>Education</summary>

* **Ph.D. program in Center for Electronics and Electrical Engineering,**
  **School of Integrated Design Engineering,**
  **Graduate School of Keio University** (Apr. 2021 – present in Japan) <br>
  *My research theme is about human motion analysis and removing scene bias in action recognition. (Adviser: Prof. Yoshimitsu AOKI. [Lab Homepage](https://aoki-medialab.jp/))*

* **M.S. in Center for Electronics and Electrical Engineering,**
  **School of Integrated Design Engineering,**
  **Graduate School of Keio University** (Apr. 2019 – Mar. 2021 in Japan) <br>
  *My research theme is about human motion analysis and object function detection. I’m expected to get a master’s degree in 2021. (Adviser: Prof. Yoshimitsu AOKI. [Lab Homepage](https://aoki-medialab.jp/))*

* **B.S. in Dept. of Electronics and Electrical Engineering,**
  **Keio University** (Apr. 2015 - Mar.2019 in Japan) <br>
  *I mainly studied Electronics in the first three years. During the last year, I researched Machine Learning, Computer Vision and Robot Vision. (Adviser: Prof. Yoshimitsu AOKI. [Lab Homepage](https://aoki-medialab.jp/))*

</details>

<!-- Experience -->
<details>
<summary>Experience</summary>

* **Machine Learning Engineer in [Softbank Corp.](https://www.softbank.jp/en/) [Apr. 2021 - present in Tokyo, Japan]**<br>
  Computer Vision / Edge Device Development

* **Backend Engineer developing [AIC website](https://aic.keio.ac.jp/forStudents/web) [Sep. 2020 - preseent in Japan]**<br>

* **Internship in [Tenchijin Inc.](https://tenchijin.co.jp/) [Jun. 2020 – Mar. 2021  in Tokyo, Japan]**<br>
  Backend / Machine Learning Engineer working on the analysis of the big data about space.

* **Internship in [CyberAgent, Inc.](https://www.cyberagent.co.jp/en/) [Feb. 2020 - Feb. 2020  Tokyo, Japan]**<br>
  Worked on developing AdTech using machine learning and GCP.

* **Internship in [SoftBank Corp.](https://www.softbank.jp/en/) [Aug. 2019 – Sep. 2019 in Tokyo, Japan]**<br>
  Worked on the following two task:<br>
  1. classifying a product into normal one or abnormal one and visualizing where a CNN model looks<br>
  2. semantic segmentation for super high-resolution images<br>

* **Research Assisstant in [National Institute of Advanced Industrial Science and Technology(AIST)](https://www.aist.go.jp/index_en.html) [Apr. 2019 – Mar. 2021 in Tsukuba, Ibaraki, Japan]**<br>
  Research about Machine Learning and Action Recognition under the supervision of [Ph.D. Hirokatsu KATAOKA](http://hirokatsukataoka.net/).

* **Internship in [IBM Japan, Ltd.](https://www.ibm.com/ibm/jp/en/) [Sep. 2018 - Mar. 2019 in Tokyo, Japan]**<br>
  Worked on weakly-supervised affordance detection using the hierarchy between affordances and objects.

</details>

<!-- Publications -->
<details>
<summary>Publications</summary>

#### Journal

* **石川裕地**，石川晴也，秋月秀一，青木義満，操作タスク入力に基づく物体の機能部推定, 精密工学会 85巻12号 (2019年12月5日発行)

#### International Conference

* Kensho Hara, **Yuchi Ishikawa**, Hirokatsu Kataoka, "Rethinking Training Data for Mitigating Representation Biases in Action Recognition" in CVPR 2021 Workshop on Large Scale Holistic Video Understanding 2021

* **Yuchi Ishikawa**, Seito Kasai, Yoshimitsu Aoki, Hirokatsu kataoka, "Alleviating Over-segmentation Errors by Detecting Action Boundaries" in WACV 2021. [arXiv](https://arxiv.org/abs/2007.06866)

* Seito Kasai, **Yuchi Ishikawa**, Masaki Hayashi, Yoshimitsu Aoki, Kensho Hara, Hirokatsu Kataoka
, “RETRIEVING AND HIGHLIGHTING ACTION WITH SPATIOTEMPORAL REFERENCE” in IEEE ICIP 2020. [arXiv](https://arxiv.org/abs/2005.09183?context=cs)

* **Yuchi Ishikawa**, Haruya Ishikawa, Shuichi Akizuki, Masaki Yamazaki, Yasuhiro Taniguchi, Yoshimitsu Aoki, "Task-oriented Function Detection Based on Operational Tasks" in Conference: 2019 19th International Conference on Advanced Robotics (ICAR). (Acceptance Rate 55.3%)

* Seito Kasai\*, **Yuchi Ishikawa\***, Tenga Wakamiya, Kensho Hara, Hirokatsu Kataoka, “AIST Team submission for Task 3, Dense-Captioning Events in Videos,”  in CVPR 2019 Workshop, International Challenge on ActivityNet Challenge, 2019.

* Tenga Wakamiya, Kensho Hara, **Yuchi Ishikawa**, Seito Kasai, Hirokatsu Kataoka, “AIST Submission for ActivityNet Challenge 2019 in Trimmed Activity Recognition (Kinetics),” in CVPR 2019 Workshop, International Challenge on ActivityNet Challenge, 2019.

* Haruya Ishikawa, **Yuchi Ishikawa**, Shuichi Akizuki, Yoshimitsu Aoki, "Human-Object Maps for Daily Activity Recognition" in International Conference on Machine Vision Applications(MVA 2019)

#### Domestic Conference

* **石川裕地**，石川晴也，秋月秀一，青木義満，Action Segmentation における損失関数の検証，第26回画像センシングシンポジウム(SSII 2020)

* Seito KASAI, **Yuchi ISHIKAWA**, Tenga WAKAMIYA, Kensho HARA, Hirokatsu KATAOKA, Exploring the Best Model for Dense Captioning Events in Videos, 第22回画像の認識・理解シンポジウム (MIRU2019)

* 若宮天雅，原健翔，**石川裕地**，笠井誠斗，中村 明生，片岡 裕雄，超大規模データセットによる動画像認識のための学習済みモデルの構築，第22回画像の認識・理解シンポジウム (MIRU2019)

* **石川裕地**，石川晴也，秋月秀一，青木義満，ロボットの物体操作のためのタスク指向な機能部の推定，第22回画像の認識・理解シンポジウム (MIRU2019)

* 秋月秀一，**石川裕地**，石川晴也，青木義満，物体の配置記述に基づくシーン復元のための操作方法推定，第25回画像センシングシンポジウム(SSII 2019)

* **石川裕地**，石川晴也，秋月秀一，青木義満，操作タスクと指示対象クラスの入力による物体の機能部推定，第25回画像センシングシンポジウム(SSII 2019)

* **石川裕地**，石川晴也，秋月秀一，青木義満，操作タスク入力に基づく物体の機能部推定，動的画像処理実利用化ワークショップ2019(DIA 2019)

* 秋月秀一，**石川裕地**，石川晴也，青木義満，非定常状態の理解とシーン復元のための物体の操作方法推定，動的画像処理実利用化ワークショップ2019(DIA 2019)
</details>

<!-- Projects -->
<details>
<summary>Projects</summary>

* **[cvpaper.challenge 研究効率化 Tips](https://www.slideshare.net/cvpaperchallenge/cvpaperchallenge-tips-241914101)**
  I wrote about how to efficiently manage experiment results.

* **[RADTorch](https://github.com/radtorch/radtorch) Contributor**<br>
  My codes for explainable AI are used in RADTorch.

* **[CVPR2019速報](https://www.slideshare.net/cvpaperchallenge/cvpr-2019)**<br>
  I took part in CVPR 2019 and wrote this article with members of cvpaper.challenge.

* **[cvpaper.challenge](http://xpaperchallenge.org/cv/) [Apr. 2019 – present]**<br>
  As a member of cvpaper.challenge, I read a lot of papers accepted at CVPR or several top conferences. I also reseach and share the knowledge with its members.

* **[ActivityNet Challenge](http://activity-net.org/) [Jun. 2019]**<br>
  Out team took part in ActivityNet Challenge in CVPR workshop. We won 9th place in Task A - Trimmed Action Recognition. Our team also participated in Task 3 - Dense-Captioning Events in Videos.

* **[Paper Summary](https://github.com/yiskw713/paper_summary)**<br>
  I read papers every day and summarize them as far as possible in GitHub. If you get interested, visit [my project page](https://github.com/yiskw713/paper_summary).

</details>

<!-- Article -->
<details>
<summary>Articles</summary>

* **Interview with a manager of the AI department in Softbank**<br>
  [SF映画の世界はもう実現している？ ソフトバンク AI部門 部長とAI専攻学生の対談](https://www.softbank.jp/sbnews/entry/20191108_01)

</details>

<!-- Recognition -->
<details>
<summary>Recognition</summary>

* **[AWS Cloud Practitioner](https://aws.amazon.com/jp/certification/certified-cloud-practitioner/) [Jul. 2021]**

* **[Python 3 エンジニア認定基礎試験](https://www.pythonic-exam.com/exam/basic) [Jul. 2021]**

* **[Practical Algorithm Skill Test](https://past.atcoder.jp/) [May. 2020]**<br>
  Rank: ADVANCED (the second highest rank)

* **[Information Technology Passport Examination (IT Passport)](https://www3.jitec.ipa.go.jp/JitesCbt/index.html) [Jan. 2020]**<br>
  National Examination on Information Technology in Japan

* **[JDLA Deep Learning for GENERAL](https://www.jdla.org/en/) [Jul. 2019]**<br>
  JDLA aims to develop Deep Learning Generalist, capable of utilizing in business, which has sufficient knowledge in Deep Leaning.

* **Outstanding Performance Award for Bachelor Theses [Mar. 2019]**<br>
  My bachelor thesis topic is “Task-oriented Function Detection Based on Operational Tasks”.
  I proposed an alternative representation to Affordance, “Task-oriented Function”, in the paper. This representation makes it possible to desribe a variety of ways to use an object, though only one usage can be described in Affordance Detection in the field of Computer Vision.

* **3rd place award in MIRU 2018 Young Researchers Program [Aug. 2018]**<br>
  As a young researcher program in MIRU 2018, participants were divided into several groups and each group read papers in the field outside Computer Vision. Then, each group summarized the history, the trend and the conection with Computer Vision. It helped us not only understand different fields, but also consider how we can make use of knowledge about them for Computer Vision.<br>
  Our group, C, read papers in the field of Robotics, focusing on “Transferring Knowledge from Simulation to Real”. You can see our poster and presentation material from [this link](https://sites.google.com/view/miru2018sapporo/wakate_top/%E5%90%84%E3%83%81%E3%83%BC%E3%83%A0%E3%81%AE%E7%99%BA%E8%A1%A8%E8%B3%87%E6%96%99?authuser=0).

* **[TOEIC](https://www.iibc-global.org/english.html) [May 2018]**<br>
  Score: 940

</details>

<!-- Grants -->
<details>
<summary>Grants</summary>

* **[慶応工学会育英奨学生](http://www.keiokougakukai.org/) [Apr. 2021 - Mar. 2022]**

* **[Scholarship of Japan Student Services Organization](https://www.jasso.go.jp/shogakukin/index.html) [Apr. 2019 - Mar. 2021]**<br>
  This educational lender have been totally exempted because my achievement during master program was highly evaluated.

* **JEES・ソフトバンクAI人材育成奨学金 [Apr. 2019 - Mar. 2020]**<br>
  I received this scholorship which aims at supporting up to a hundred of capable students studying Artificial Intelligence in Japan.

</details>

### GitHub Streaks 🏃‍♂️

[![GitHub Streak](http://github-readme-streak-stats.herokuapp.com?user=yiskw713&theme=gotham&hide_border=true)](https://git.io/streak-stats)

### GitHub Stats ✨

<img align="left" src="https://github-readme-stats.vercel.app/api?username=yiskw713&count_private=true&show_icons=true&theme=gotham&include_all_commits=true" />
<img src="https://github-readme-stats.vercel.app/api/top-langs/?username=yiskw713&hide=jupyter%20notebook&layout=compact&theme=gotham" />

<br />

### GitHub Trophy 🏆

[![trophy](https://github-profile-trophy.vercel.app/?username=yiskw713&theme=alduin&column=8)](https://github.com/ryo-ma/github-profile-trophy)

### Latest Blog Posts 📕

<!-- BLOG-POST-LIST:START -->
- [Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?を読んだのでメモ](https://yiskw713.hatenablog.com/entry/2021/07/13/074728)
- [【Python】del 文について](https://yiskw713.hatenablog.com/entry/2021/06/30/080354)
- [【Python】モジュール内でそのモジュールへの参照を取得する](https://yiskw713.hatenablog.com/entry/2021/06/25/200000)
- [【PyTorch】nn.Sequentialで動画の前処理を行う](https://yiskw713.hatenablog.com/entry/2021/06/20/232513)
- [【Rust】順列，組み合わせ，重複組み合わせを列挙する](https://yiskw713.hatenablog.com/entry/2021/06/20/200752)
<!-- BLOG-POST-LIST:END -->

### GitHub Activities

<!--START_SECTION:activity-->
1. ❗️ Opened issue [#170](https://github.com/yiskw713/paper_summary/issues/170) in [yiskw713/paper_summary](https://github.com/yiskw713/paper_summary)
2. ❗️ Opened issue [#169](https://github.com/yiskw713/paper_summary/issues/169) in [yiskw713/paper_summary](https://github.com/yiskw713/paper_summary)
3. ❗️ Opened issue [#168](https://github.com/yiskw713/paper_summary/issues/168) in [yiskw713/paper_summary](https://github.com/yiskw713/paper_summary)
4. ❗️ Opened issue [#167](https://github.com/yiskw713/paper_summary/issues/167) in [yiskw713/paper_summary](https://github.com/yiskw713/paper_summary)
5. ❗️ Opened issue [#166](https://github.com/yiskw713/paper_summary/issues/166) in [yiskw713/paper_summary](https://github.com/yiskw713/paper_summary)
<!--END_SECTION:activity-->

### WakaTime Stats ⌚️

<!--START_SECTION:waka-->
![Lines of code](https://img.shields.io/badge/From%20Hello%20World%20I%27ve%20Written-22.1%20million%20lines%20of%20code-blue)

**🐱 My Github Data** 

> 🏆 399 Contributions in the Year 2021
 > 
> 📦 11.9 MB Used in Github's Storage 
 > 
> 💼 Opted to Hire
 > 
> 📜 49 Public Repositories 
 > 
> 🔑 68 Private Repositories  
 > 
**I'm an Early 🐤** 

```text
🌞 Morning    91 commits     ██████░░░░░░░░░░░░░░░░░░░   26.84% 
🌆 Daytime    146 commits    ██████████░░░░░░░░░░░░░░░   43.07% 
🌃 Evening    91 commits     ██████░░░░░░░░░░░░░░░░░░░   26.84% 
🌙 Night      11 commits     ░░░░░░░░░░░░░░░░░░░░░░░░░   3.24%

```
📅 **I'm Most Productive on Tuesday** 

```text
Monday       48 commits     ███░░░░░░░░░░░░░░░░░░░░░░   14.16% 
Tuesday      69 commits     █████░░░░░░░░░░░░░░░░░░░░   20.35% 
Wednesday    41 commits     ███░░░░░░░░░░░░░░░░░░░░░░   12.09% 
Thursday     58 commits     ████░░░░░░░░░░░░░░░░░░░░░   17.11% 
Friday       57 commits     ████░░░░░░░░░░░░░░░░░░░░░   16.81% 
Saturday     28 commits     ██░░░░░░░░░░░░░░░░░░░░░░░   8.26% 
Sunday       38 commits     ██░░░░░░░░░░░░░░░░░░░░░░░   11.21%

```


📊 **This Week I Spent My Time On** 

```text
💬 Programming Languages: 
Rust                     10 hrs 38 mins      ███████████████░░░░░░░░░░   62.51% 
Python                   5 hrs 53 mins       ████████░░░░░░░░░░░░░░░░░   34.62% 
Other                    12 mins             ░░░░░░░░░░░░░░░░░░░░░░░░░   1.22% 
Markdown                 8 mins              ░░░░░░░░░░░░░░░░░░░░░░░░░   0.83% 
TOML                     4 mins              ░░░░░░░░░░░░░░░░░░░░░░░░░   0.43%

🔥 Editors: 
VS Code                  17 hrs 2 mins       █████████████████████████   100.0%

```

**I Mostly Code in Python** 

```text
Python                   60 repos            ████████████████░░░░░░░░░   64.52% 
Jupyter Notebook         17 repos            ████░░░░░░░░░░░░░░░░░░░░░   18.28% 
HTML                     4 repos             █░░░░░░░░░░░░░░░░░░░░░░░░   4.3% 
Shell                    3 repos             ░░░░░░░░░░░░░░░░░░░░░░░░░   3.23% 
JavaScript               3 repos             ░░░░░░░░░░░░░░░░░░░░░░░░░   3.23%

```


**Timeline**

![Chart not found](https://raw.githubusercontent.com/yiskw713/yiskw713/master/charts/bar_graph.png) 


<!--END_SECTION:waka-->


[website]: https://yiskw713.github.io
[twitter]: https://twitter.com/yciskw_
[instagram]: https://www.instagram.com/yciskw_/
[linkedin]: https://www.linkedin.com/in/yiskw713/
[facebook]: https://www.facebook.com/yuchi.ishikawa.7
[blog]: https://yiskw713.hatenablog.com/
